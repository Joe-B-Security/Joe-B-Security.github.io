---
title: "Awesome Prompt Injection: Open for contributions!"
date: 2024-12-16
description: "A curated collection of everything you need to understand and test prompt injection attacks"
tags: ["Prompt Injection", "AI Security", "Open Source", "Resources"]
---

## What's Inside

I built [Awesome Prompt Injection](https://github.com/Joe-B-Security/awesome-prompt-injection) - a curated collection of everything worth knowing about AI manipulation attacks.

The repo is organized around what people actually need:

**Research & Articles**: The foundational knowledge, from academic papers to real-world case studies

**Tools**: Everything from Token Turbulenz (fuzzing framework) to Garak (automated weakness detection) to InjectLab (attack technique matrix)

**CTF Challenges**: Hands-on practice scenarios that simulate real prompt injection attacks

**Community Resources**: Discord servers, forums, and other places where this stuff gets discussed

## Why It Matters

AI security isn't just about preventing jailbreaks anymore. We're building systems that can execute code, access databases, and make real-world decisions.

If you're building AI applications, you need to know how they can be attacked. If you're a researcher, you need to see what's already been tried. If you're just curious, you need somewhere to start that isn't a random Twitter thread.

## Get Involved

Found a resource I missed? See something that's out of date? The repo is open for contributions.

[Check out Awesome Prompt Injection on GitHub](https://github.com/Joe-B-Security/awesome-prompt-injection)
